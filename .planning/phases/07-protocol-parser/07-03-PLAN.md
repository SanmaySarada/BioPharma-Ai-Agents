---
phase: 07-protocol-parser
plan: 03
type: execute
wave: 3
depends_on: ["07-02"]
files_modified:
  - src/omni_agents/cli.py
  - src/omni_agents/agents/__init__.py
  - tests/test_pipeline/test_protocol_parser.py
autonomous: false

must_haves:
  truths:
    - "User can run `omni-agents parse-protocol protocol.docx -o config.yaml` and get a config file"
    - "CLI displays a Rich table showing all extracted values with source (extracted/default) for each field"
    - "Fields that fell back to defaults are visually flagged in the display"
    - "User is prompted for confirmation before config is written"
    - "Config is written as valid YAML that Settings.from_yaml() can load"
  artifacts:
    - path: "src/omni_agents/cli.py"
      provides: "parse-protocol CLI subcommand"
      contains: "def parse_protocol"
    - path: "tests/test_pipeline/test_protocol_parser.py"
      provides: "Integration tests for parse-protocol flow"
      contains: "class TestParseProtocolCLI"
  key_links:
    - from: "src/omni_agents/cli.py"
      to: "src/omni_agents/agents/protocol_parser.py"
      via: "ProtocolParserAgent.parse()"
      pattern: "ProtocolParserAgent"
    - from: "src/omni_agents/cli.py"
      to: "src/omni_agents/config.py"
      via: "ExtractionResult display + YAML write"
      pattern: "ExtractionResult"
    - from: "src/omni_agents/cli.py"
      to: "config.yaml output"
      via: "yaml.dump of TrialConfig"
      pattern: "yaml\\.dump"
---

<objective>
Wire the Protocol Parser Agent into the CLI as a `parse-protocol` subcommand and build the Rich confirmation display that shows extracted vs defaulted values before writing config.

Purpose: This is the user-facing entry point (PARSE-05) and the confirmation display (PARSE-04). The confirmation step is non-negotiable for regulated biostatistics -- PITFALL-01 shows LLMs achieve only 49-66% accuracy on numeric extraction, so the user MUST verify every value.

Output: Updated cli.py with parse-protocol subcommand, Rich confirmation display, YAML config writer, and integration tests.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md (PARSE-01 through PARSE-05)
@.planning/research/PITFALLS.md (PITFALL-01 mandatory human confirmation, PITFALL-04 defaults flagging)
@.planning/research/ARCHITECTURE.md (CLI integration pattern, parse-protocol subcommand)
@.planning/research/FEATURES.md (Feature 1: separate subcommand, not flag on run)

@.planning/phases/07-protocol-parser/07-01-SUMMARY.md
@.planning/phases/07-protocol-parser/07-02-SUMMARY.md

@src/omni_agents/cli.py (existing Typer CLI with run command)
@src/omni_agents/config.py (TrialConfig, ProtocolExtraction, ExtractionResult, Settings)
@src/omni_agents/agents/protocol_parser.py (ProtocolParserAgent from Plan 02)
@src/omni_agents/agents/__init__.py (agent exports)
@src/omni_agents/llm/gemini.py (GeminiAdapter -- default LLM for extraction)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add parse-protocol CLI subcommand with Rich confirmation display</name>
  <files>
    src/omni_agents/cli.py
    src/omni_agents/agents/__init__.py
  </files>
  <action>
**1a. Add `parse-protocol` subcommand to `src/omni_agents/cli.py`:**

Add a new `@app.command()` function below the existing `run` command. This is a SEPARATE subcommand (not a flag on `run`) per the architecture decision in FEATURES.md.

```python
@app.command("parse-protocol")
def parse_protocol(
    protocol: Path = typer.Argument(
        ...,
        help="Path to .docx protocol document",
        exists=True,
    ),
    output: Path = typer.Option(
        "config.yaml",
        "--output",
        "-o",
        help="Output path for generated config YAML",
    ),
    config: Path = typer.Option(
        None,
        "--config",
        "-c",
        help="Base config YAML (for LLM settings). Uses env vars if not provided.",
        exists=True,
    ),
    yes: bool = typer.Option(
        False,
        "--yes",
        "-y",
        help="Skip confirmation prompt and write config immediately",
    ),
) -> None:
    """Parse a clinical trial protocol document into pipeline config.

    Reads a .docx protocol document, extracts trial parameters using
    an LLM, and writes a config.yaml file compatible with the pipeline.

    Example:
        omni-agents parse-protocol protocol.docx -o config.yaml
    """
```

Implementation flow:
1. Load LLM settings: If `--config` provided, load Settings and use the Gemini adapter. If not, create a GeminiAdapter from env vars (`GEMINI_API_KEY`).
2. Create ProtocolParserAgent with the Gemini adapter.
3. Run `asyncio.run(agent.parse(protocol))` to get ExtractionResult.
4. Call `_display_extraction(result, console)` to show Rich table.
5. If not `--yes`: prompt user with `Confirm.ask("Write this config?")`. If declined, exit.
6. Write config YAML via `_write_config(result.config, output)`.
7. Print success message with output path.

**1b. Implement `_display_extraction()` helper in cli.py:**

This is the critical PARSE-04 confirmation display. Uses Rich Table to show each field with its value and source (extracted vs default).

```python
from rich.console import Console
from rich.table import Table
from rich.prompt import Confirm


def _display_extraction(result: "ExtractionResult", console: Console) -> None:
    """Display extracted protocol values in a Rich table.

    Shows each field's value and whether it was extracted from the
    document or fell back to the default. Defaulted fields are
    highlighted in yellow as a warning (PITFALL-01, PITFALL-04).
    """
    table = Table(
        title="Protocol Extraction Results",
        show_header=True,
        header_style="bold",
    )
    table.add_column("Field", style="cyan")
    table.add_column("Value", style="white")
    table.add_column("Source", style="white")

    config_dict = result.config.model_dump()

    for field_name in sorted(config_dict.keys()):
        value = config_dict[field_name]
        if field_name in result.extracted_fields:
            source = "[green]extracted[/green]"
        else:
            source = "[yellow]DEFAULT[/yellow]"
        table.add_row(field_name, str(value), source)

    console.print()
    console.print(table)

    # Summary warning if many defaults
    n_defaults = len(result.defaulted_fields)
    n_total = len(config_dict)
    if n_defaults > 0:
        console.print(
            f"\n[yellow]Warning:[/yellow] {n_defaults}/{n_total} fields "
            f"used defaults (not found in protocol document)."
        )
        if n_defaults > n_total // 2:
            console.print(
                "[yellow]More than half the fields were not found. "
                "Review the protocol document for completeness.[/yellow]"
            )
    console.print()
```

**1c. Implement `_write_config()` helper in cli.py:**

```python
def _write_config(trial_config: "TrialConfig", output_path: Path) -> None:
    """Write a TrialConfig as a YAML config file.

    Produces a config.yaml that Settings.from_yaml() can load.
    Only writes the trial section -- LLM and Docker config must
    be provided separately (via env vars or base config).
    """
    import yaml

    config_data = {
        "trial": trial_config.model_dump(),
        "llm": {
            "gemini": {
                "api_key": "$GEMINI_API_KEY",
                "model": "gemini-2.5-pro",
                "temperature": 0.0,
            },
            "openai": {
                "api_key": "$OPENAI_API_KEY",
                "model": "gpt-4o",
                "temperature": 0.0,
            },
        },
    }

    output_path.write_text(yaml.dump(config_data, default_flow_style=False, sort_keys=False))
```

**1d. Wire LLM adapter creation in parse_protocol():**

```python
# Inside parse_protocol():
import os

if config is not None:
    from omni_agents.config import Settings
    settings = Settings.from_yaml(config)
    gemini_config = settings.llm.gemini
else:
    from omni_agents.config import GeminiConfig
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        console = Console()
        console.print("[red]Error:[/red] GEMINI_API_KEY not set. "
                      "Provide --config or set the environment variable.")
        raise typer.Exit(code=1)
    gemini_config = GeminiConfig(api_key=api_key)

from omni_agents.llm.gemini import GeminiAdapter
from omni_agents.agents.protocol_parser import ProtocolParserAgent

llm = GeminiAdapter(gemini_config)
prompt_dir = Path(__file__).parent / "templates" / "prompts"
agent = ProtocolParserAgent(llm=llm, prompt_dir=prompt_dir)

console = Console()
try:
    result = asyncio.run(agent.parse(protocol))
except Exception as e:
    console.print(f"[red]Error parsing protocol:[/red] {e}")
    raise typer.Exit(code=1) from None

_display_extraction(result, console)

if not yes:
    if not Confirm.ask("Write this config?", default=True, console=console):
        console.print("[yellow]Aborted.[/yellow] Config not written.")
        raise typer.Exit(code=0)

_write_config(result.config, output)
console.print(f"[green]Config written to {output}[/green]")
console.print(f"Run: [bold]omni-agents run -c {output}[/bold]")
```

**1e. Update `src/omni_agents/agents/__init__.py`:**

Add ProtocolParserAgent to the exports:

```python
from omni_agents.agents.protocol_parser import ProtocolParserAgent

__all__ = [..., "ProtocolParserAgent"]
```
  </action>
  <verify>
Run `python -m omni_agents parse-protocol --help` -- shows usage with protocol argument, --output, --config, --yes options.
Run `python -c "from omni_agents.agents import ProtocolParserAgent; print('OK')"` -- import works.
Run `pytest tests/ -v` -- all existing tests pass.
  </verify>
  <done>
parse-protocol CLI subcommand exists with protocol argument, --output/-o, --config/-c, and --yes/-y options. Rich table displays all fields with extracted/default source. Defaulted fields flagged yellow. Confirmation prompt before writing. Config written as valid YAML with $ENV_VAR placeholders for API keys.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integration tests for parse-protocol flow</name>
  <files>
    tests/test_pipeline/test_protocol_parser.py
  </files>
  <action>
Create `tests/test_pipeline/test_protocol_parser.py` with integration tests for the end-to-end parse-protocol flow. These tests mock the LLM call but test everything else end-to-end.

```python
"""Tests for the Protocol Parser Agent and CLI integration."""
import asyncio
import json
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
import yaml

from omni_agents.agents.protocol_parser import ProtocolParserAgent
from omni_agents.config import (
    ExtractionResult,
    ProtocolExtraction,
    TrialConfig,
    merge_extraction,
)
```

**Test classes:**

**`TestProtocolParserAgent`:**

- `test_parse_calls_extract_protocol_text`: Mock extract_protocol_text and LLM, verify extract_protocol_text called with the correct path
- `test_parse_calls_generate_structured`: Mock LLM, verify generate_structured called with ProtocolExtraction as response_model
- `test_parse_returns_extraction_result`: Mock LLM to return a ProtocolExtraction with some fields set, verify ExtractionResult has correct extracted/defaulted fields
- `test_parse_with_custom_defaults`: Pass a non-default TrialConfig, verify non-extracted fields use those defaults
- `test_parse_file_not_found`: Passing a non-existent path raises FileNotFoundError

For all tests that mock the LLM:
```python
mock_llm = MagicMock()
mock_llm.generate_structured = AsyncMock(return_value=ProtocolExtraction(
    n_subjects=500,
    treatment_sbp_mean=115.0,
    dropout_rate=0.15,
))
```

And mock extract_protocol_text:
```python
with patch("omni_agents.agents.protocol_parser.extract_protocol_text") as mock_extract:
    mock_extract.return_value = "Protocol text with 500 subjects..."
    result = asyncio.run(agent.parse(Path("fake.docx")))
```

**`TestDisplayExtraction`:**

- `test_display_shows_all_fields`: Mock Console, call _display_extraction, verify table has rows for all TrialConfig fields
- `test_display_flags_defaults_yellow`: Verify defaulted fields show "[yellow]DEFAULT[/yellow]"
- `test_display_shows_extracted_green`: Verify extracted fields show "[green]extracted[/green]"
- `test_display_warns_on_many_defaults`: When >50% defaulted, verify warning message printed

**`TestWriteConfig`:**

- `test_write_config_creates_valid_yaml`: Write config to tmp_path, read back, verify valid YAML
- `test_write_config_has_trial_section`: Verify trial section present with all TrialConfig fields
- `test_write_config_has_env_var_placeholders`: Verify LLM api_key fields use $GEMINI_API_KEY / $OPENAI_API_KEY
- `test_written_config_roundtrips`: Write config, set env vars, load with Settings.from_yaml(), verify trial values match

**`TestParseProtocolCLI`:**

- `test_help_output`: Use typer.testing.CliRunner, invoke with --help, verify "parse-protocol" in output
- `test_missing_protocol_arg`: Invoke with no args, verify exit code != 0

Use `typer.testing.CliRunner` for CLI tests:
```python
from typer.testing import CliRunner
from omni_agents.cli import app

runner = CliRunner()

def test_help_output():
    result = runner.invoke(app, ["parse-protocol", "--help"])
    assert result.exit_code == 0
    assert "protocol" in result.output.lower()
```
  </action>
  <verify>
Run `pytest tests/test_pipeline/test_protocol_parser.py -v` -- all tests pass.
Run `pytest tests/ -v` -- full suite passes, no regressions.
  </verify>
  <done>
Integration tests cover: ProtocolParserAgent.parse() wiring, extraction display output, config YAML writing with roundtrip validation, and CLI help/argument validation. All tests pass using mocked LLM (no API calls needed).
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
Complete parse-protocol CLI flow: .docx input -> LLM extraction -> Rich confirmation table -> YAML config output.

This implements all PARSE requirements:
- PARSE-01: .docx input -> config.yaml output
- PARSE-02: Extracts all TrialConfig fields
- PARSE-03: Pydantic validation on extraction
- PARSE-04: Rich table confirmation display with default flagging
- PARSE-05: parse-protocol CLI subcommand
  </what-built>
  <how-to-verify>
1. Run `omni-agents parse-protocol --help` and verify the command shows usage info
2. If you have a sample .docx protocol document, test the full flow:
   ```
   export GEMINI_API_KEY=your-key
   omni-agents parse-protocol your_protocol.docx -o test_config.yaml
   ```
3. Verify the Rich table displays all 14 fields with extracted/default indicators
4. Verify defaulted fields are flagged yellow
5. Verify confirmation prompt appears ("Write this config?")
6. Verify config.yaml is written and contains valid YAML
7. Run `pytest tests/ -v` and verify all tests pass
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
1. `omni-agents parse-protocol --help` -- shows subcommand with all options
2. Rich table displays all TrialConfig fields with extracted/default source
3. Defaulted fields flagged yellow; extracted fields shown green
4. User prompted for confirmation before config is written (skippable with --yes)
5. Output config.yaml is valid YAML loadable by Settings.from_yaml()
6. `pytest tests/ -v` -- all tests pass including new integration tests
7. Requirement traceability: PARSE-01 through PARSE-05 all addressed
</verification>

<success_criteria>
- `omni-agents parse-protocol protocol.docx -o config.yaml` works end-to-end
- Rich table shows all 14 fields with value and source (extracted/default)
- Defaulted fields visually flagged (PITFALL-04 addressed)
- User confirmation required before writing (PITFALL-01 addressed)
- Config YAML output is valid and loadable
- All existing + new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/07-protocol-parser/07-03-SUMMARY.md`
</output>
