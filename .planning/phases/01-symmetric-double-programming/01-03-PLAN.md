---
phase: 01-symmetric-double-programming
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/omni_agents/pipeline/orchestrator.py
  - src/omni_agents/display/callbacks.py
  - src/omni_agents/agents/double_programmer.py
autonomous: true

must_haves:
  truths:
    - "Both Track A and Track B run the full SDTM -> ADaM -> Stats pipeline independently"
    - "Track A uses GeminiAdapter, Track B uses OpenAIAdapter, both use the same agent classes and prompts"
    - "_run_track is a single generic method parameterized by track_id and llm"
    - "Track B output directory mirrors Track A structure (track_b/sdtm/, track_b/adam/, track_b/stats/)"
    - "Script cache keys include track_id preventing cross-track cache collisions"
    - "DoubleProgrammerAgent is marked deprecated but not deleted"
    - "Callback step names are track-qualified (sdtm_track_a, sdtm_track_b, etc.)"
    - "Pipeline state records track-qualified step names (sdtm_track_a, adam_track_b, etc.) via _record_step after each agent"
  artifacts:
    - path: "src/omni_agents/pipeline/orchestrator.py"
      provides: "Symmetric orchestrator with generic _run_track method"
      contains: "async def _run_track"
    - path: "src/omni_agents/display/callbacks.py"
      provides: "ProgressCallback protocol (unchanged interface, updated docs)"
      exports: ["ProgressCallback"]
    - path: "src/omni_agents/agents/double_programmer.py"
      provides: "Deprecated DoubleProgrammerAgent"
      contains: "deprecated"
  key_links:
    - from: "src/omni_agents/pipeline/orchestrator.py"
      to: "src/omni_agents/models/resolution.py"
      via: "imports TrackResult for _run_track return type"
      pattern: "from omni_agents.models.resolution import TrackResult"
    - from: "src/omni_agents/pipeline/orchestrator.py"
      to: "src/omni_agents/pipeline/script_cache.py"
      via: "passes track_id to cache_key"
      pattern: "cache_key.*track_id"
---

<objective>
Refactor the orchestrator from asymmetric tracks (Track A: full pipeline, Track B: DoubleProgrammerAgent) to symmetric tracks where both tracks run the full SDTM -> ADaM -> Stats pipeline via a generic _run_track method.

Purpose: This is the core architectural change. After this plan, both tracks independently produce the same output structure (sdtm/, adam/, stats/ with DM.csv, VS.csv, ADTTE.rds, ADTTE_summary.json, results.json). The consensus comparison and resolution (Plan 04) depend on this symmetric output.

Output: Refactored orchestrator.py with generic _run_track, deprecated DoubleProgrammerAgent, track-qualified callbacks.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-symmetric-double-programming/01-RESEARCH.md

# Prior plan artifacts needed (models from Plan 01):
@src/omni_agents/models/resolution.py

# Files being modified:
@src/omni_agents/pipeline/orchestrator.py
@src/omni_agents/display/callbacks.py
@src/omni_agents/agents/double_programmer.py

# Referenced for understanding:
@src/omni_agents/agents/base.py
@src/omni_agents/agents/sdtm.py
@src/omni_agents/agents/adam.py
@src/omni_agents/agents/stats.py
@src/omni_agents/pipeline/schema_validator.py
@src/omni_agents/pipeline/script_cache.py
@src/omni_agents/llm/base.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor orchestrator to generic _run_track</name>
  <files>src/omni_agents/pipeline/orchestrator.py</files>
  <action>
This is the largest task. Modify `src/omni_agents/pipeline/orchestrator.py` to replace the asymmetric `_run_track_a` and `_run_track_b` with a single generic `_run_track` method. Preserve ALL existing behavior for Track A -- this is a refactor, not a rewrite.

**Step 1: Add imports**

Add at the top:
```python
from omni_agents.models.resolution import TrackResult
```

Remove the import of `DoubleProgrammerAgent` (it is no longer used in the orchestrator).

**Step 2: Update `_run_agent` to accept track_id for cache key**

In the `_run_agent` method, add a `track_id: str = ""` parameter. Update the cache_key line:
```python
# Old:
cache_key = ScriptCache.cache_key(self.settings.trial, agent.name)
# New:
cache_key = ScriptCache.cache_key(self.settings.trial, agent.name, track_id)
```

**Step 3: Create generic `_run_track` method**

Replace `_run_track_a` and `_run_track_b` with a single method. The new method is a direct generalization of `_run_track_a` -- same structure, same agent instantiation pattern, same schema validation calls, but parameterized by track_id and llm.

Signature:
```python
async def _run_track(
    self,
    track_id: str,       # "track_a" or "track_b"
    llm: BaseLLM,        # GeminiAdapter or OpenAIAdapter
    raw_dir: Path,
    output_dir: Path,
    prompt_dir: Path,
    state: PipelineState,
    state_path: Path,
) -> TrackResult:
```

Body: Directly adapt `_run_track_a`. CRITICAL changes (all three are required):

1. Replace hardcoded "track_a" with `track_id` parameter everywhere.
2. Replace hardcoded `gemini` with `llm` parameter.
3. Track-qualify callback step_names: use `f"{stage}_{track_id}"` format (e.g., "sdtm_track_a", "adam_track_b").
4. Track-qualify state step names: use `f"{stage}_{track_id}"` (e.g., "sdtm_track_a").
5. **CRITICAL -- Pass `track_id=track_id` to EVERY `self._run_agent()` call.** This prevents the Pitfall 6 cache key collision. Without this, Track A and Track B get the same cache key and Track B silently reuses Track A's Gemini-generated script.
6. **CRITICAL -- Call `self._record_step()` after EVERY agent completes**, exactly as `_run_track_a` does. Use track-qualified step names.

Here is the complete body showing all `_run_agent` and `_record_step` calls explicitly:

```python
async def _run_track(
    self,
    track_id: str,
    llm: BaseLLM,
    raw_dir: Path,
    output_dir: Path,
    prompt_dir: Path,
    state: PipelineState,
    state_path: Path,
) -> TrackResult:
    """Run full SDTM -> ADaM -> Stats pipeline for one track."""
    track_dir = output_dir / track_id

    # === SDTM Agent ===
    sdtm_dir = track_dir / "sdtm"
    sdtm_dir.mkdir(parents=True, exist_ok=True)
    sdtm_agent = SDTMAgent(
        llm=llm, prompt_dir=prompt_dir, trial_config=self.settings.trial
    )
    if self.callback:
        self.callback.on_step_start(f"sdtm_{track_id}", "SDTMAgent", track_id)
    t0 = time.monotonic()
    _stdout, sdtm_attempts = await self._run_agent(
        agent=sdtm_agent,
        context={
            "input_path": "/workspace/input/SBPdata.csv",
            "output_dir": "/workspace",
        },
        work_dir=sdtm_dir,
        input_volumes={str(raw_dir): "/workspace/input"},
        expected_inputs=["/workspace/input/SBPdata.csv"],
        expected_outputs=["DM.csv", "VS.csv"],
        track_id=track_id,
    )
    duration = time.monotonic() - t0
    self._record_step(
        state, state_path, f"sdtm_{track_id}", "SDTMAgent", track_id, sdtm_attempts
    )
    if self.callback:
        self.callback.on_step_complete(f"sdtm_{track_id}", duration, len(sdtm_attempts))
    SchemaValidator.validate_sdtm(sdtm_dir, self.settings.trial.n_subjects)
    logger.info(f"SDTM schema validation passed ({track_id})")

    # === ADaM Agent ===
    adam_dir = track_dir / "adam"
    adam_dir.mkdir(parents=True, exist_ok=True)
    adam_agent = ADaMAgent(
        llm=llm, prompt_dir=prompt_dir, trial_config=self.settings.trial
    )
    if self.callback:
        self.callback.on_step_start(f"adam_{track_id}", "ADaMAgent", track_id)
    t0 = time.monotonic()
    _stdout, adam_attempts = await self._run_agent(
        agent=adam_agent,
        context={
            "input_dir": "/workspace/input",
            "output_dir": "/workspace",
        },
        work_dir=adam_dir,
        input_volumes={str(sdtm_dir): "/workspace/input"},
        expected_inputs=["DM.csv", "VS.csv"],
        expected_outputs=["ADTTE.rds", "ADTTE_summary.json"],
        track_id=track_id,
    )
    duration = time.monotonic() - t0
    self._record_step(
        state, state_path, f"adam_{track_id}", "ADaMAgent", track_id, adam_attempts
    )
    if self.callback:
        self.callback.on_step_complete(f"adam_{track_id}", duration, len(adam_attempts))
    SchemaValidator.validate_adam(adam_dir, self.settings.trial.n_subjects)
    logger.info(f"ADaM schema validation passed ({track_id})")

    # === Stats Agent ===
    stats_dir = track_dir / "stats"
    stats_dir.mkdir(parents=True, exist_ok=True)
    stats_agent = StatsAgent(
        llm=llm, prompt_dir=prompt_dir, trial_config=self.settings.trial
    )
    if self.callback:
        self.callback.on_step_start(f"stats_{track_id}", "StatsAgent", track_id)
    t0 = time.monotonic()
    _stdout, stats_attempts = await self._run_agent(
        agent=stats_agent,
        context={
            "adam_dir": "/workspace/adam",
            "sdtm_dir": "/workspace/sdtm",
            "output_dir": "/workspace",
        },
        work_dir=stats_dir,
        input_volumes={
            str(adam_dir): "/workspace/adam",
            str(sdtm_dir): "/workspace/sdtm",
        },
        expected_inputs=["ADTTE.rds", "DM.csv"],
        expected_outputs=["results.json", "km_plot.png"],
        track_id=track_id,
    )
    duration = time.monotonic() - t0
    self._record_step(
        state, state_path, f"stats_{track_id}", "StatsAgent", track_id, stats_attempts
    )
    if self.callback:
        self.callback.on_step_complete(f"stats_{track_id}", duration, len(stats_attempts))
    SchemaValidator.validate_stats(stats_dir)
    logger.info(f"Stats schema validation passed ({track_id})")

    return TrackResult(
        track_id=track_id,
        sdtm_dir=sdtm_dir,
        adam_dir=adam_dir,
        stats_dir=stats_dir,
        results_path=stats_dir / "results.json",
    )
```

Note every `_run_agent` call includes `track_id=track_id`. Note every agent is followed by a `_record_step` call with track-qualified name `f"{stage}_{track_id}"`. These are NOT optional -- omitting them breaks cache isolation (Pitfall 6) and pipeline state tracking respectively.

**Step 4: Delete `_run_track_a` and `_run_track_b`**

Remove both methods entirely. They are replaced by `_run_track`.

**Step 5: Update `run()` method**

In the `run()` method, update the fork section (Step 2) to use `_run_track`:

```python
# Old:
track_a_result, track_b_result = await asyncio.gather(
    self._run_track_a(raw_dir, output_dir, gemini, prompt_dir, state, state_path),
    self._run_track_b(raw_dir, output_dir, openai, prompt_dir, state, state_path),
)

# New:
track_a_result, track_b_result = await asyncio.gather(
    self._run_track("track_a", gemini, raw_dir, output_dir, prompt_dir, state, state_path),
    self._run_track("track_b", openai, raw_dir, output_dir, prompt_dir, state, state_path),
)
```

Note: `track_a_result` and `track_b_result` are now `TrackResult` objects, not `Path` objects.

**Step 6: Update consensus step to use TrackResult**

The consensus comparison currently does:
```python
verdict = ConsensusJudge.compare(track_a_result, track_b_result)
```
where both args were Paths. Now they are TrackResult objects.

For NOW (before Plan 04 replaces this with StageComparator), update to:
```python
verdict = ConsensusJudge.compare(track_a_result.results_path, track_b_result.results_path)
```

This preserves the existing ConsensusJudge behavior temporarily. Plan 04 will replace this with stage-by-stage comparison.

**Important note:** The ConsensusJudge.compare() method expects track_a_path (Path to results.json) and track_b_path (Path to validation.json). With symmetric tracks, Track B now also produces results.json, NOT validation.json. The ConsensusJudge currently reads different keys from track_a (table2.logrank_p, table3.cox_hr, metadata.*) vs track_b (validator_p_value, validator_hr, metadata.*).

For the TEMPORARY bridge until Plan 04:
- Track B now produces results.json with the same structure as Track A.
- ConsensusJudge.compare() won't work correctly because it expects track_b to have "validator_p_value" and "validator_hr" keys.
- Create a TEMPORARY bridge: add a `compare_symmetric` classmethod to ConsensusJudge that accepts two results.json Paths and reads the same keys from both. OR, modify the `run()` method to skip the old consensus comparison and instead just save a placeholder verdict (with `Verdict.PASS` and empty comparisons) -- Plan 04 will replace this entirely with StageComparator + ResolutionLoop.

Recommended approach: Add a `compare_symmetric` classmethod to `ConsensusJudge` in `pipeline/consensus.py` that reads both files as results.json format (same keys). This is a small bridge method:

```python
@classmethod
def compare_symmetric(cls, track_a_results: Path, track_b_results: Path) -> ConsensusVerdict:
    """Compare two results.json files (symmetric tracks).

    Temporary bridge method until StageComparator replaces ConsensusJudge.
    Both files have identical structure (table2, table3, metadata).
    """
    track_a = json.loads(track_a_results.read_text())
    track_b = json.loads(track_b_results.read_text())

    # Use same comparison logic but read same keys from both
    # ... (same as existing compare() but read table2/table3/metadata from both)
```

Actually, the CLEANEST approach: update `run()` to call `ConsensusJudge.compare_symmetric(track_a_result.results_path, track_b_result.results_path)`. Add `compare_symmetric` to `pipeline/consensus.py` -- it's identical to `compare()` except it reads both files using the Track A key paths (table2.logrank_p, table3.cox_hr, metadata.*) instead of the Track B-specific keys (validator_p_value, validator_hr).

Add this `compare_symmetric` method to `src/omni_agents/pipeline/consensus.py`. It reads the same JSON structure from both paths.

**Step 7: Update class and module docstrings**

Update the module docstring and PipelineOrchestrator class docstring to reflect symmetric architecture. Remove references to DoubleProgrammerAgent and Track B "independent validation." Mention generic _run_track, stage-by-stage comparison (coming in Plan 04), and resolution loop (coming in Plan 04).

Update the `run()` method docstring similarly.
  </action>
  <verify>
Run: `cd /Users/sanmaysarada/omni-ai-agents && python -c "from omni_agents.pipeline.orchestrator import PipelineOrchestrator; print('Orchestrator importable'); print([m for m in dir(PipelineOrchestrator) if not m.startswith('__')])"` -- should show _run_track but NOT _run_track_a or _run_track_b.

Also verify: `python -c "from omni_agents.pipeline.consensus import ConsensusJudge; print(hasattr(ConsensusJudge, 'compare_symmetric'))"` -- should print True.

Also verify track_id flows through to _run_agent: `cd /Users/sanmaysarada/omni-ai-agents && python -c "import inspect; from omni_agents.pipeline.orchestrator import PipelineOrchestrator; src = inspect.getsource(PipelineOrchestrator._run_track); assert src.count('track_id=track_id') >= 3, f'Expected 3+ track_id=track_id in _run_track, found {src.count(\"track_id=track_id\")}'; print(f'track_id=track_id appears {src.count(\"track_id=track_id\")} times -- OK')"` -- should show 3+ occurrences (one per _run_agent call).

Also verify _record_step calls: `cd /Users/sanmaysarada/omni-ai-agents && python -c "import inspect; from omni_agents.pipeline.orchestrator import PipelineOrchestrator; src = inspect.getsource(PipelineOrchestrator._run_track); assert src.count('_record_step') >= 3, f'Expected 3+ _record_step in _run_track, found {src.count(\"_record_step\")}'; print(f'_record_step appears {src.count(\"_record_step\")} times -- OK')"` -- should show 3 occurrences (one per agent).
  </verify>
  <done>Orchestrator has single _run_track method (no _run_track_a or _run_track_b). _run_track accepts track_id and BaseLLM, returns TrackResult. Every _run_agent call passes track_id=track_id for cache key isolation. Every agent is followed by _record_step with track-qualified name. run() calls _run_track("track_a", gemini, ...) and _run_track("track_b", openai, ...) in parallel. ConsensusJudge.compare_symmetric reads same-format results.json from both tracks.</done>
</task>

<task type="auto">
  <name>Task 2: Deprecate DoubleProgrammerAgent and update callbacks</name>
  <files>
    src/omni_agents/agents/double_programmer.py
    src/omni_agents/display/callbacks.py
  </files>
  <action>
**Update `src/omni_agents/agents/double_programmer.py`:**

1. Add a deprecation warning to the module docstring:
   ```
   .. deprecated:: Phase 1 Symmetric Double Programming
       This agent is deprecated. Both tracks now use SDTMAgent, ADaMAgent, and
       StatsAgent independently. The DoubleProgrammerAgent produced a simplified
       validation.json instead of the full SDTM -> ADaM -> Stats pipeline.
       Kept for backward compatibility.
   ```

2. Add `import warnings` at the top.

3. In `DoubleProgrammerAgent.__init__`, add:
   ```python
   warnings.warn(
       "DoubleProgrammerAgent is deprecated. Both tracks now run the full "
       "SDTM -> ADaM -> Stats pipeline independently using SDTMAgent, "
       "ADaMAgent, and StatsAgent.",
       DeprecationWarning,
       stacklevel=2,
   )
   ```

Do NOT delete the class or the template file. Keep for backward compat.

**Update `src/omni_agents/display/callbacks.py`:**

1. Update the docstring for `on_step_start` to document track-qualified step names:
   ```
   Args:
       step_name: Identifier for the step. With symmetric tracks, step names
           are track-qualified: ``"sdtm_track_a"``, ``"adam_track_b"``, etc.
           Shared steps use unqualified names: ``"simulator"``, ``"consensus"``.
       agent_type: Class name of the agent (e.g. ``"SDTMAgent"``).
       track: Pipeline track (``"shared"``, ``"track_a"``, ``"track_b"``).
   ```

2. Add a new optional method `on_resolution_start` to the Protocol:
   ```python
   def on_resolution_start(self, stage: str, iteration: int, max_iterations: int) -> None:
       """Called when resolution begins for a disagreeing stage.

       Args:
           stage: Pipeline stage being resolved ("sdtm", "adam", "stats").
           iteration: Current resolution iteration (1-indexed).
           max_iterations: Maximum iterations allowed.
       """
       ...
   ```

3. Add `on_resolution_complete` to the Protocol:
   ```python
   def on_resolution_complete(self, stage: str, resolved: bool, iterations: int) -> None:
       """Called when resolution finishes for a stage.

       Args:
           stage: Pipeline stage that was resolved.
           resolved: True if tracks now agree.
           iterations: Total resolution iterations performed.
       """
       ...
   ```

These are Protocol methods with `...` body (no default impl needed -- Protocol pattern).
  </action>
  <verify>
Run: `cd /Users/sanmaysarada/omni-ai-agents && python -c "import warnings; warnings.simplefilter('always'); from omni_agents.agents.double_programmer import DoubleProgrammerAgent; print('Import OK')"`

Then: `cd /Users/sanmaysarada/omni-ai-agents && python -c "from omni_agents.display.callbacks import ProgressCallback; print(hasattr(ProgressCallback, 'on_resolution_start')); print(hasattr(ProgressCallback, 'on_resolution_complete'))"`

Then: `cd /Users/sanmaysarada/omni-ai-agents && python -m pytest tests/ -v` -- all existing tests pass.
  </verify>
  <done>DoubleProgrammerAgent emits DeprecationWarning on instantiation. ProgressCallback protocol has on_resolution_start and on_resolution_complete methods. All existing tests pass.</done>
</task>

</tasks>

<verification>
1. `python -c "from omni_agents.pipeline.orchestrator import PipelineOrchestrator; print([m for m in dir(PipelineOrchestrator) if 'track' in m])"` -- shows only _run_track
2. `python -c "from omni_agents.pipeline.consensus import ConsensusJudge; print(hasattr(ConsensusJudge, 'compare_symmetric'))"` -- True
3. `python -c "from omni_agents.models.resolution import TrackResult; print(TrackResult.__fields__.keys())"` -- TrackResult used in orchestrator
4. `python -m pytest tests/ -v` -- all tests pass
5. Grep for `_run_track_a` and `_run_track_b` in orchestrator.py -- should return nothing
6. Grep for `DoubleProgrammerAgent` in orchestrator.py -- should return nothing (removed import)
7. Grep for `track_id=track_id` in orchestrator.py _run_track method -- should appear 3 times (once per _run_agent call)
8. Grep for `_record_step` in orchestrator.py _run_track method -- should appear 3 times (once per agent)
</verification>

<success_criteria>
- orchestrator.py has _run_track (generic) and NOT _run_track_a or _run_track_b
- _run_track accepts track_id (str) and llm (BaseLLM), returns TrackResult
- EVERY _run_agent call in _run_track passes track_id=track_id (3 occurrences: SDTM, ADaM, Stats)
- EVERY agent in _run_track is followed by _record_step with track-qualified name f"{stage}_{track_id}" (3 occurrences)
- Both tracks run SDTM -> ADaM -> Stats with schema validation at each stage
- Track B output goes to track_b/sdtm/, track_b/adam/, track_b/stats/ (mirroring Track A)
- Script cache keys include track_id (different tracks produce different cache keys)
- Callback step names are track-qualified (sdtm_track_a, sdtm_track_b)
- ConsensusJudge.compare_symmetric works with same-format results.json from both tracks
- DoubleProgrammerAgent emits DeprecationWarning
- ProgressCallback has on_resolution_start and on_resolution_complete
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/01-symmetric-double-programming/01-03-SUMMARY.md`
</output>
