---
phase: 06-interactive-execution-mode
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/omni_agents/display/callbacks.py
  - src/omni_agents/display/pipeline_display.py
  - src/omni_agents/display/interactive_display.py
  - src/omni_agents/pipeline/orchestrator.py
  - src/omni_agents/cli.py
  - tests/test_display/__init__.py
  - tests/test_display/test_interactive_display.py
autonomous: true

must_haves:
  truths:
    - "Running with --interactive flag pauses after each logical stage and shows a summary panel"
    - "Running without --interactive flag behaves identically to current behavior (no pauses, no regressions)"
    - "User presses Enter to continue or Ctrl+C to abort at each pause point"
    - "Rich Live display resumes correctly after each pause (progress bars retain state)"
    - "Non-interactive terminals (CI, piped stdin) skip pauses automatically via EOFError handling"
  artifacts:
    - path: "src/omni_agents/display/callbacks.py"
      provides: "InteractiveCallback protocol with async on_checkpoint method"
      contains: "class InteractiveCallback"
    - path: "src/omni_agents/display/interactive_display.py"
      provides: "InteractivePipelineDisplay subclass with Rich Panel summaries and run_in_executor input"
      exports: ["InteractivePipelineDisplay"]
    - path: "src/omni_agents/display/pipeline_display.py"
      provides: "Idempotent start() that preserves Progress instances across stop/start cycles"
      contains: "if self._progress is None"
    - path: "src/omni_agents/pipeline/orchestrator.py"
      provides: "_checkpoint() method called at 4 pause points in run()"
      contains: "_checkpoint"
    - path: "src/omni_agents/cli.py"
      provides: "--interactive / -i CLI flag that selects InteractivePipelineDisplay"
      contains: "interactive"
    - path: "tests/test_display/test_interactive_display.py"
      provides: "Tests for checkpoint flow, EOFError handling, Ctrl+C handling, non-interactive bypass"
  key_links:
    - from: "src/omni_agents/cli.py"
      to: "src/omni_agents/display/interactive_display.py"
      via: "conditional instantiation based on --interactive flag"
      pattern: "InteractivePipelineDisplay"
    - from: "src/omni_agents/pipeline/orchestrator.py"
      to: "src/omni_agents/display/callbacks.py"
      via: "isinstance check in _checkpoint()"
      pattern: "isinstance.*InteractiveCallback"
    - from: "src/omni_agents/display/interactive_display.py"
      to: "src/omni_agents/display/pipeline_display.py"
      via: "subclass calling self.stop()/self.start() around input"
      pattern: "self\\.stop\\(\\)|self\\.start\\(\\)"
---

<objective>
Add interactive execution mode to the clinical trial pipeline so users can review output step-by-step before each stage proceeds.

Purpose: Users inspecting pipeline output (simulator data, track results, comparison verdicts) need pause points to verify intermediate results before committing to subsequent expensive stages. This is table stakes for any multi-stage pipeline used in regulated workflows.

Output: A working `--interactive` CLI flag that pauses after each logical stage (simulator, parallel tracks, comparison, resolution), displays a Rich Panel summary with metrics and file paths, and waits for Enter to continue or Ctrl+C to abort. Non-interactive mode remains the default and is completely unaffected.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/research/ARCHITECTURE.md (Feature 3 section)
@.planning/research/PITFALLS.md (PITFALL-03, PITFALL-07, PITFALL-09, PITFALL-11)
@.planning/research/FEATURES.md (Feature 3 section)
@src/omni_agents/display/callbacks.py
@src/omni_agents/display/pipeline_display.py
@src/omni_agents/pipeline/orchestrator.py
@src/omni_agents/cli.py
@src/omni_agents/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: InteractiveCallback protocol + idempotent display restart + InteractivePipelineDisplay</name>
  <files>
    src/omni_agents/display/callbacks.py
    src/omni_agents/display/pipeline_display.py
    src/omni_agents/display/interactive_display.py
  </files>
  <action>
Three changes in the display/callback layer:

**1. Add InteractiveCallback protocol to callbacks.py**

Add a new protocol class BELOW the existing ProgressCallback (do NOT modify ProgressCallback itself -- existing implementations must remain valid):

```python
@runtime_checkable
class InteractiveCallback(ProgressCallback, Protocol):
    """Extended callback protocol for interactive execution mode.

    Adds checkpoint support to ProgressCallback. The orchestrator calls
    on_checkpoint() at stage boundaries when running in interactive mode.
    Non-interactive callbacks do not implement this and are unaffected.
    """

    async def on_checkpoint(
        self,
        stage_name: str,
        summary: dict[str, str | list[str]],
    ) -> bool:
        """Called at interactive pause points between pipeline stages.

        Args:
            stage_name: Human-readable name of the completed stage
                (e.g., "Simulator", "Parallel Analysis", "Stage Comparison").
            summary: Dict with keys like "status", "duration", "output_files",
                "metrics" -- contents vary per stage.

        Returns:
            True to continue pipeline execution, False to abort.
        """
        ...
```

**2. Refactor PipelineDisplay.start() for idempotent restart (PITFALL-07 fix)**

The current `start()` creates a new `Progress` instance and new task IDs every call. If `stop()` then `start()` is called mid-pipeline, the progress bars reset and old task references break.

Refactor `start()` so it only creates `Progress` and task IDs on the FIRST call. On subsequent calls, it only recreates the `Live` context:

```python
def start(self) -> None:
    """Start the Live display (interactive mode only).

    Safe to call multiple times -- Progress instances and task IDs are
    created only once. Subsequent calls restart only the Live context.
    """
    if self._progress is None:
        self._progress = self._build_progress()
        self._track_a_task = self._progress.add_task("Track A", total=3)
        self._track_b_task = self._progress.add_task("Track B", total=3)

    if self._interactive:
        from rich.live import Live

        renderable = self._build_renderable()
        self._live = Live(
            renderable, console=self.console, refresh_per_second=4
        )
        self._live.start()
```

This is the ONLY change to pipeline_display.py. The conditional `if self._progress is None:` guards ensure Progress/task state survives stop/start cycles.

**3. Create InteractivePipelineDisplay in new file interactive_display.py**

Create `src/omni_agents/display/interactive_display.py`:

```python
"""Interactive pipeline display with stage-level pause points.

Extends PipelineDisplay with checkpoint support: stops the Rich Live
display, shows a summary panel, waits for user input via
run_in_executor (non-blocking to the event loop), then restarts
the Live display.
"""

import asyncio
import sys

from rich.panel import Panel
from rich.table import Table

from omni_agents.display.callbacks import InteractiveCallback
from omni_agents.display.pipeline_display import PipelineDisplay


class InteractivePipelineDisplay(PipelineDisplay):
    """Pipeline display with interactive pause points between stages.

    Implements InteractiveCallback by stopping Rich Live, rendering a
    summary panel, and waiting for Enter (via run_in_executor to avoid
    blocking the asyncio event loop).

    Non-TTY environments (CI, piped stdin) are detected via EOFError
    from input() -- pauses are silently skipped.
    """

    async def on_checkpoint(
        self,
        stage_name: str,
        summary: dict[str, str | list[str]],
    ) -> bool:
        """Pause pipeline and display stage summary.

        Stops Rich Live, prints a summary panel, waits for Enter.
        Returns True to continue, False to abort.

        Handles:
        - EOFError: stdin is not a TTY (CI) -- auto-continue
        - KeyboardInterrupt: Ctrl+C during pause -- abort
        """
        self.stop()

        # Build summary panel
        table = Table(show_header=False, show_edge=False, pad_edge=False, expand=True)
        table.add_column("Key", style="bold", ratio=1)
        table.add_column("Value", ratio=3)

        for key, value in summary.items():
            if isinstance(value, list):
                display_value = "\n".join(str(v) for v in value)
            else:
                display_value = str(value)
            table.add_row(key.replace("_", " ").title(), display_value)

        panel = Panel(
            table,
            title=f"[bold]Stage Complete: {stage_name}[/bold]",
            border_style="cyan",
            subtitle="[dim]Press Enter to continue, Ctrl+C to abort[/dim]",
        )
        self.console.print()
        self.console.print(panel)

        # Wait for user input via run_in_executor (INTER-05: non-blocking)
        try:
            loop = asyncio.get_running_loop()
            await loop.run_in_executor(None, input)
        except EOFError:
            # Non-interactive terminal (CI, piped stdin) -- auto-continue
            # PITFALL-09: Interactive mode must not break CI
            self.console.print("[dim]Non-interactive terminal detected, continuing...[/dim]")
        except KeyboardInterrupt:
            # PITFALL-11: Graceful Ctrl+C during pause
            self.console.print("\n[yellow]Pipeline aborted by user at checkpoint.[/yellow]")
            return False

        self.start()
        return True
```

This class satisfies the InteractiveCallback protocol through duck typing (runtime_checkable). It inherits all ProgressCallback methods from PipelineDisplay.

IMPORTANT implementation notes:
- Use `asyncio.get_running_loop()` (not `get_event_loop()` which is deprecated in 3.12+)
- The `input()` call with no prompt argument is intentional -- the Rich Panel subtitle already shows the prompt text. A bare `input()` just waits for Enter.
- EOFError handling covers PITFALL-09 (CI/piped stdin auto-continues)
- KeyboardInterrupt handling covers PITFALL-11 (graceful abort returns False)
- `self.stop()` before input and `self.start()` after covers PITFALL-07 and INTER-06 (Rich Live lifecycle)
  </action>
  <verify>
Run: `python -c "from omni_agents.display.callbacks import InteractiveCallback, ProgressCallback; from omni_agents.display.interactive_display import InteractivePipelineDisplay; d = InteractivePipelineDisplay(); assert isinstance(d, InteractiveCallback); print('OK')"`

Also verify PipelineDisplay idempotent restart:
`python -c "from omni_agents.display.pipeline_display import PipelineDisplay; d = PipelineDisplay(); d._interactive = False; d.start(); p1 = id(d._progress); d.stop(); d.start(); p2 = id(d._progress); assert p1 == p2, f'Progress recreated: {p1} != {p2}'; print('OK: Progress preserved across stop/start')"`
  </verify>
  <done>
InteractiveCallback protocol exists in callbacks.py without modifying ProgressCallback. PipelineDisplay.start() is idempotent (Progress/task IDs survive stop/start cycles). InteractivePipelineDisplay renders Rich Panel summaries and handles Enter/EOFError/KeyboardInterrupt correctly. isinstance(InteractivePipelineDisplay(), InteractiveCallback) returns True.
  </done>
</task>

<task type="auto">
  <name>Task 2: Orchestrator _checkpoint() + CLI --interactive flag + tests</name>
  <files>
    src/omni_agents/pipeline/orchestrator.py
    src/omni_agents/cli.py
    tests/test_display/__init__.py
    tests/test_display/test_interactive_display.py
  </files>
  <action>
Three changes: orchestrator checkpoint integration, CLI flag, and tests.

**1. Add _checkpoint() method and 4 checkpoint calls to orchestrator.py**

Add a private async method to PipelineOrchestrator:

```python
async def _checkpoint(self, stage_name: str, summary: dict[str, str | list[str]]) -> None:
    """Pause for user confirmation if callback supports interactive mode.

    No-op when callback is None or is a plain ProgressCallback (non-interactive).
    Only pauses when callback is an InteractiveCallback instance.

    Args:
        stage_name: Human-readable stage name for the summary panel.
        summary: Key-value pairs to display (status, files, metrics).

    Raises:
        KeyboardInterrupt: If user aborts at checkpoint.
    """
    from omni_agents.display.callbacks import InteractiveCallback

    if self.callback is not None and isinstance(self.callback, InteractiveCallback):
        should_continue = await self.callback.on_checkpoint(stage_name, summary)
        if not should_continue:
            raise KeyboardInterrupt("User aborted at interactive checkpoint")
```

Add the import at the top of the file is NOT needed -- the import is inside the method to avoid circular imports and to keep the import lazy (only when interactive mode is actually used).

Then add 4 checkpoint calls in `run()` at the natural phase boundaries. Insert them at these exact locations:

**Checkpoint 1: After Simulator validation (after line ~468, after `logger.info("Simulator output validated")`)**
```python
        # Interactive checkpoint: after simulator
        await self._checkpoint("Simulator", {
            "status": "Simulation complete",
            "output_files": [str(output_csv)],
            "metrics": f"{self.settings.trial.n_subjects} subjects, {self.settings.trial.visits} visits",
            "next_stage": "Parallel Analysis (Track A + Track B)",
        })
```

**Checkpoint 2: After asyncio.gather returns (after line ~483, after `logger.info(f"Parallel execution completed...")`)**

Build a summary that lists output directories for both tracks:
```python
        # Interactive checkpoint: after parallel tracks
        await self._checkpoint("Parallel Analysis", {
            "status": "Both tracks complete",
            "duration": f"{t_parallel:.1f}s",
            "output_files": [
                str(track_a_result.sdtm_dir),
                str(track_a_result.adam_dir),
                str(track_a_result.stats_dir),
                str(track_b_result.sdtm_dir),
                str(track_b_result.adam_dir),
                str(track_b_result.stats_dir),
            ],
            "next_stage": "Stage Comparison",
        })
```

**Checkpoint 3: After StageComparator and verdict determination (after the verdict is saved to verdict_path and the consensus step is recorded in state, just BEFORE the `if verdict.verdict == Verdict.HALT:` check around line ~649)**

```python
        # Interactive checkpoint: after comparison (and resolution if triggered)
        checkpoint_summary = {
            "status": f"Verdict: {verdict.verdict.value}",
            "output_files": [str(verdict_path), str(stage_comparisons_path)],
            "next_stage": "Medical Writer (CSR Generation)",
        }
        if resolution_result is not None:
            checkpoint_summary["resolution"] = (
                f"{'Resolved' if resolution_result.resolved else 'Unresolved'} "
                f"after {resolution_result.iterations} iteration(s)"
            )
        await self._checkpoint("Comparison & Resolution", checkpoint_summary)
```

Place this checkpoint BEFORE the HALT check so the user sees the verdict before the pipeline halts (if HALT, the raise will happen after checkpoint).

**Checkpoint 4: After Medical Writer (OPTIONAL -- skip this one).** The Medical Writer is the final step. There is nothing to continue to, so a pause here adds no value. The existing `on_pipeline_complete` callback handles the final summary. Do NOT add a checkpoint after Medical Writer.

So: 3 checkpoints total (after simulator, after parallel tracks, after comparison/resolution).

**2. Add --interactive flag to cli.py**

Modify the `run` command:

```python
@app.command()
def run(
    config: Path = _config_option,
    interactive: bool = typer.Option(
        False,
        "--interactive",
        "-i",
        help="Pause between pipeline stages for step-by-step review",
    ),
) -> None:
    """Run the clinical trial pipeline."""
    from omni_agents.config import Settings
    from omni_agents.display.error_display import ErrorDisplay
    from omni_agents.display.pipeline_display import PipelineDisplay

    settings = Settings.from_yaml(config)

    # Create display infrastructure -- interactive mode uses extended display
    if interactive:
        from omni_agents.display.interactive_display import InteractivePipelineDisplay
        display = InteractivePipelineDisplay()
    else:
        display = PipelineDisplay()

    error_display = ErrorDisplay(display.console)

    orchestrator = PipelineOrchestrator(
        settings, callback=display, console=display.console
    )

    try:
        display.start()
        asyncio.run(orchestrator.run())
        display.stop()
    except KeyboardInterrupt:
        display.stop()
        error_display.show_error(
            "pipeline",
            "interrupted",
            "Pipeline interrupted by user",
            "Re-run with the same config to resume",
        )
        raise typer.Exit(code=130) from None
    except Exception as e:
        display.stop()
        agent_name, error_class, message, suggestion = (
            ErrorDisplay.format_pipeline_error(e)
        )
        error_display.show_error(agent_name, error_class, message, suggestion)
        raise typer.Exit(code=1) from None
```

The import of PipelineOrchestrator is already inside the function body from existing code. Add the conditional import of InteractivePipelineDisplay inside the `if interactive:` branch to keep the lazy import pattern.

**3. Create tests in tests/test_display/test_interactive_display.py**

Create `tests/test_display/__init__.py` (empty file).

Create `tests/test_display/test_interactive_display.py` with these test cases:

```python
"""Tests for interactive pipeline display and checkpoint flow."""

import asyncio
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

from omni_agents.display.callbacks import InteractiveCallback, ProgressCallback
from omni_agents.display.interactive_display import InteractivePipelineDisplay
from omni_agents.display.pipeline_display import PipelineDisplay


class TestInteractiveCallbackProtocol:
    """Verify InteractiveCallback protocol compliance."""

    def test_interactive_display_is_interactive_callback(self):
        display = InteractivePipelineDisplay()
        assert isinstance(display, InteractiveCallback)

    def test_interactive_display_is_progress_callback(self):
        display = InteractivePipelineDisplay()
        assert isinstance(display, ProgressCallback)

    def test_plain_display_is_not_interactive_callback(self):
        display = PipelineDisplay()
        assert not isinstance(display, InteractiveCallback)


class TestPipelineDisplayIdempotentRestart:
    """Verify PipelineDisplay.start() preserves Progress across stop/start."""

    def test_progress_preserved_across_restart(self):
        display = PipelineDisplay()
        display._interactive = False  # Avoid Live display in tests
        display.start()
        progress_id = id(display._progress)
        track_a_id = display._track_a_task
        track_b_id = display._track_b_task

        display.stop()
        display.start()

        assert id(display._progress) == progress_id
        assert display._track_a_task == track_a_id
        assert display._track_b_task == track_b_id

    def test_progress_created_on_first_start(self):
        display = PipelineDisplay()
        display._interactive = False
        assert display._progress is None
        display.start()
        assert display._progress is not None


class TestInteractiveCheckpoint:
    """Test the on_checkpoint method behavior."""

    @pytest.mark.asyncio
    async def test_checkpoint_continues_on_enter(self):
        """User presses Enter -> returns True (continue)."""
        display = InteractivePipelineDisplay()
        display._interactive = False  # No Live display

        with patch("omni_agents.display.interactive_display.input", return_value=""):
            result = await display.on_checkpoint(
                "Simulator",
                {"status": "complete", "output_files": ["/tmp/SBPdata.csv"]},
            )
        assert result is True

    @pytest.mark.asyncio
    async def test_checkpoint_aborts_on_keyboard_interrupt(self):
        """Ctrl+C during pause -> returns False (abort)."""
        display = InteractivePipelineDisplay()
        display._interactive = False

        with patch(
            "omni_agents.display.interactive_display.input",
            side_effect=KeyboardInterrupt,
        ):
            result = await display.on_checkpoint(
                "Simulator", {"status": "complete"},
            )
        assert result is False

    @pytest.mark.asyncio
    async def test_checkpoint_auto_continues_on_eof(self):
        """Non-interactive terminal (CI) -> EOFError -> returns True."""
        display = InteractivePipelineDisplay()
        display._interactive = False

        with patch(
            "omni_agents.display.interactive_display.input",
            side_effect=EOFError,
        ):
            result = await display.on_checkpoint(
                "Simulator", {"status": "complete"},
            )
        assert result is True

    @pytest.mark.asyncio
    async def test_checkpoint_renders_summary_panel(self):
        """Verify the summary dict is rendered (no crash on various key types)."""
        display = InteractivePipelineDisplay()
        display._interactive = False

        summary = {
            "status": "Both tracks complete",
            "duration": "45.2s",
            "output_files": ["/tmp/track_a/sdtm", "/tmp/track_b/sdtm"],
            "next_stage": "Stage Comparison",
        }
        with patch("omni_agents.display.interactive_display.input", return_value=""):
            result = await display.on_checkpoint("Parallel Analysis", summary)
        assert result is True


class TestOrchestratorCheckpoint:
    """Test _checkpoint integration in orchestrator."""

    @pytest.mark.asyncio
    async def test_checkpoint_noop_without_interactive_callback(self):
        """Non-interactive callback: _checkpoint is a no-op."""
        from omni_agents.pipeline.orchestrator import PipelineOrchestrator

        mock_settings = MagicMock()
        mock_callback = MagicMock(spec=ProgressCallback)

        orchestrator = PipelineOrchestrator.__new__(PipelineOrchestrator)
        orchestrator.callback = mock_callback

        # Should not raise, should not call anything
        await orchestrator._checkpoint("test", {"status": "ok"})

    @pytest.mark.asyncio
    async def test_checkpoint_calls_interactive_callback(self):
        """Interactive callback: _checkpoint calls on_checkpoint."""
        from omni_agents.pipeline.orchestrator import PipelineOrchestrator

        mock_callback = AsyncMock(spec=InteractivePipelineDisplay)
        mock_callback.on_checkpoint = AsyncMock(return_value=True)

        orchestrator = PipelineOrchestrator.__new__(PipelineOrchestrator)
        orchestrator.callback = mock_callback

        await orchestrator._checkpoint("test", {"status": "ok"})
        mock_callback.on_checkpoint.assert_called_once_with("test", {"status": "ok"})

    @pytest.mark.asyncio
    async def test_checkpoint_raises_on_abort(self):
        """Interactive callback returns False -> KeyboardInterrupt raised."""
        from omni_agents.pipeline.orchestrator import PipelineOrchestrator

        mock_callback = AsyncMock(spec=InteractivePipelineDisplay)
        mock_callback.on_checkpoint = AsyncMock(return_value=False)

        orchestrator = PipelineOrchestrator.__new__(PipelineOrchestrator)
        orchestrator.callback = mock_callback

        with pytest.raises(KeyboardInterrupt):
            await orchestrator._checkpoint("test", {"status": "ok"})

    @pytest.mark.asyncio
    async def test_checkpoint_noop_without_callback(self):
        """No callback at all: _checkpoint is a no-op."""
        from omni_agents.pipeline.orchestrator import PipelineOrchestrator

        orchestrator = PipelineOrchestrator.__new__(PipelineOrchestrator)
        orchestrator.callback = None

        await orchestrator._checkpoint("test", {"status": "ok"})
```

IMPORTANT: The tests use `pytest-asyncio` for async test support. Verify `pytest-asyncio` is installed. If not, add it to dev dependencies first: `pip install pytest-asyncio`. The tests also need the `asyncio_mode = "auto"` or `@pytest.mark.asyncio` decorator.

Note on the `input` mock path: The tests patch `omni_agents.display.interactive_display.input` because the `input` builtin is used directly in `on_checkpoint`. However, since `on_checkpoint` uses `loop.run_in_executor(None, input)`, the mock needs to replace the `input` reference at the module level. To make this work cleanly, import `input` at the module level in `interactive_display.py` would not work (it is a builtin). Instead, the approach in on_checkpoint should reference `input` in a way that can be patched.

The cleanest pattern: in `interactive_display.py`, the `run_in_executor` call should use a local reference that can be patched. Two options:
- Option A: Use `builtins.input` and patch `builtins.input`
- Option B: Define a module-level `_read_input` function that wraps `input()`, and patch that

Use Option B for clarity:

```python
# At module level in interactive_display.py
def _read_input() -> str:
    """Read a line from stdin. Separated for testability."""
    return input()
```

Then in `on_checkpoint`:
```python
await loop.run_in_executor(None, _read_input)
```

And in tests, patch `omni_agents.display.interactive_display._read_input`.

Update the test mocks accordingly to patch `_read_input` instead of `input`.
  </action>
  <verify>
Run: `cd /Users/sanmaysarada/omni-ai-agents && python -m pytest tests/test_display/ -v`

All tests should pass. Expected output: 8-10 tests passing.

Also verify CLI flag is registered:
`cd /Users/sanmaysarada/omni-ai-agents && python -m omni_agents run --help | grep -A2 interactive`

Expected: `--interactive / -i` flag visible with help text "Pause between pipeline stages for step-by-step review".

Also verify no regression on existing tests:
`cd /Users/sanmaysarada/omni-ai-agents && python -m pytest tests/ -v --timeout=30`
  </verify>
  <done>
Orchestrator._checkpoint() calls on_checkpoint on InteractiveCallback instances and is a no-op otherwise. Three checkpoint calls exist in orchestrator.run() (after simulator, after parallel tracks, after comparison/resolution). CLI has --interactive / -i flag that instantiates InteractivePipelineDisplay. All new tests pass. All existing tests still pass (no regressions). Running without --interactive is identical to prior behavior.
  </done>
</task>

</tasks>

<verification>
Requirements coverage check:
- INTER-01: `--interactive` CLI flag -> CLI integration in Task 2
- INTER-02: Pipeline pauses after each logical stage -> 3 checkpoint calls in orchestrator.run() in Task 2
- INTER-03: Rich Panel summary at each pause -> InteractivePipelineDisplay.on_checkpoint() in Task 1
- INTER-04: Enter to continue, Ctrl+C to abort -> on_checkpoint input handling in Task 1
- INTER-05: asyncio run_in_executor for input -> on_checkpoint uses loop.run_in_executor(None, _read_input) in Task 1
- INTER-06: Rich Live stop/restart around pauses -> on_checkpoint calls self.stop()/self.start(), idempotent restart in Task 1

Pitfall coverage:
- PITFALL-03: Pauses are BETWEEN phases in run(), NOT inside _run_track() or asyncio.gather()
- PITFALL-07: PipelineDisplay.start() refactored for idempotent restart (Progress preserved)
- PITFALL-09: EOFError from input() auto-continues (CI/non-TTY safe)
- PITFALL-11: KeyboardInterrupt during pause returns False -> raises KeyboardInterrupt in orchestrator -> caught by CLI error handler
</verification>

<success_criteria>
1. `omni-agents run -c config.yaml --interactive` pauses after simulator, parallel tracks, and comparison stages
2. Each pause shows a Rich Panel with stage name, status, output file paths, and next stage info
3. Pressing Enter at each pause resumes the pipeline and the Rich Live display (progress bars intact)
4. Pressing Ctrl+C at any pause cleanly aborts with the existing error display
5. `omni-agents run -c config.yaml` (without --interactive) works identically to before
6. `echo | omni-agents run -c config.yaml --interactive` (piped stdin) auto-continues through all pauses
7. All new tests pass, all existing 117 tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/06-interactive-execution-mode/06-01-SUMMARY.md`
</output>
